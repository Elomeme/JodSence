	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
日期	2025 年 6 月 30 日
任务安排	1. 今天先搞定开发环境的搭建，用 Conda 创建个虚拟环境，顺便配置好 Python 的环境变量，还要熟悉下 Jupyter Lab 这些工具的使用。
	2. 学习生成式大模型的基本概念，包括它在 AI 里的定位、基于 Transformer 的架构、多模态输入输出的特点，以及整个 AI 技术栈的层级关系。
	3. 了解生成式大模型的应用场景，比如在教育领域的自动备课功能、智能体模拟人类行为，还有相关开发工具的使用。
	4. 弄明白模型训练和优化的流程，包括预训练、微调、对齐三个阶段，以及一些前沿技术、局限性和未来的发展方向。
任务完成情况	1. 开发环境搭建顺利完成了，我用 Conda 创建了隔离的虚拟环境，配置好了 Python 的环境变量，现在能熟练用 Jupyter Lab 写实验代码了。通过一个线性回归的案例，我真切感受到环境隔离的重要性，避免了不少麻烦。
	2. 生成式大模型的基础概念我已经掌握了，知道它基于 Transformer 的自注意力机制，还了解了多模态输入输出（像文本、图像、音频）的特点，也清楚了机器学习、深度学习和生成式大模型之间的层级包含关系。
	3. 我了解了生成式大模型在教育领域的应用，比如自动备课和宣传片生成；还知道智能体能模拟人类行为，比如安排约会，而且可以结合工具链如搜索 API 或无头浏览器来用。我也认识了无头浏览器和 Operator 这些开发工具。
	4. 模型训练的流程我理解了，包括预训练（无监督学习）、微调（适应具体任务）和对齐（伦理和格式校准）。还知道了像脑科手术这样的前沿技术，清楚当前模型在算力、数据依赖和生成幻觉方面的局限，以及多模态融合等未来方向。
工作中的问题	1. 用 Conda 创建虚拟环境时，因为源配置出问题失败了；配置 Python 环境变量时路径设错了，导致 Python 调用不正常，真是折腾了好一会儿。
	2. 对 Transformer 架构的自注意力机制的具体计算过程和原理还把握不准，对多模态输入输出的实现方式有点困惑，感觉需要多看些例子。
	3. 学习智能体结合工具链使用时，对搜索 API 和无头浏览器的具体调用方法和集成方式不太熟悉，操作起来挺费劲的。
	4. 在理解模型训练的对齐阶段时，对伦理校准的具体标准和实施方法不是很清楚；对生成幻觉问题的 RAG 技术缓解方式的具体操作也不太了解。
总结与思考	1. 开发环境搭建是基础工作，用 Conda 时要注意源配置和环境变量设置，我可以整理些常见问题和解决方案，以后就能更高效了。
	2. 基础概念很重要，对于 Transformer 这样的复杂东西，得结合实例和可视化资料来加深理解，多想想它在实际应用中的体现。
	3. 学习应用场景能帮我把握技术方向，了解智能体和工具链结合时，可以通过实际案例来练习调用和集成，提升动手能力。
	4. 模型训练与优化是核心内容，要关注对齐阶段的伦理校准行业规范，积极探索 RAG 等技术来缓解生成幻觉这样的局限，推动技术进步
	
	
	
	
日期	2025 年 7 月 1 日
任务安排	1. LangChain 安装
	2. 阿里通义千问 API 申请与管理
	3. 通义千问模型实例创建
	4. 流式传输、工具链调用等核心技术研究
	5. 提示词工程、交互优化方法学习
完成情况	1. LangChain 安装与网络代理配置完成，成功安装依赖库
	2. 通义千问模型调用方法掌握，明确不同版本（Turbo/Plus/Max）选择策略
	3. 流式传输机制与工具链调用逻辑理解，可处理基础调用场景
	4. 提示词设计技巧（场景化、分步指令）掌握，能实现基础交互优化
工作中的问题	1. LangChain 安装时因网络代理设置不当导致下载超时
	2. API 首次调用提示权限不足
	3. 流式传输中输出卡顿或重复
	4. 提示词效果不稳定
总结与思考	1. 环境配置需制定规范流程
	2. 模型版本选择需结合实际需求
	3. 交互优化需加强练习
	4. 高级技巧使用需兼顾效果与效率
	
	
	
	
	
	
	
	
	
	
日期	2025 年 7 月 2 日
任务安排	实训规范、版本差异、多角色交互、Prompt 工程、RAG 等技术
完成情况	规范明确、对话掌握、Prompt 实践、RAG 等了解
工作中的问题	记录模糊、随机性大、泛化不足、兼容报错
总结与思考	阶段细化、权重强化、消息设计、模型升级、调试 Checklist
	
	
日期	2025 年 7 月 3 日
任务安排	1. 研究大模型现状，包括 2025 年能力边界、多模态场景，以及免费和开源工具的区别
	2. 学习提示词工程，对比设计技巧与传统方法，探索预制和自定义 Prompt 的平衡
	3. 了解大模型训练三阶段演进，到 2025 年简化为预训练 + 对齐两阶段
	4. 研究 Transformer 架构，如注意力机制、位置编码、残差连接，以及多头注意力和 RNN 的并行差异
任务完成情况	1. 初步了解大模型现状，清楚 2025 年多模态拓展，免费工具简单易用，开源更灵活
	2. 掌握 Prompt 设计技巧，比传统高效，对预制和自定义的平衡有点心得
	3. 清楚训练阶段演进，2025 年简化成两阶段，原因主要是效率提升
	4. 基本理解 Transformer 核心，如注意力、位置编码；能区分多头注意力和 RNN 的并行优势
工作中的问题	1. 2025 年多模态实现不清晰，判断可行性难
	2. Prompt 平衡把握不好，预制僵化，自定义太乱
	3. 多头注意力原理不深，RNN 对比分析不到位
	4. 词嵌入兼容性困惑，缺乏案例
总结与思考	1. 大模型发展快，多关注案例和动态，才能实际应用，真是日新月异
	2. 提示词关键，多练平衡技巧，提升输出质量
	3. Transformer 是核心，多看文档源码，加深理解，为应用打基础
	4. 词嵌入兼容需注意方案特点，提前选型测试，避免项目坑
	
项目	内容
日期	2025 年 7 月 4 日
任务安排	1、研究 LAN chain 访问大模型的实现方式，增强大模型能力。
	2、配置智能体 (Agent) 功能，实现大模型调用搜索引擎的二次优化输出。
	3、对比分析不同搜索引擎 API，完成 API 选择与配置。
	4、尝试使用 RAG 增强生成技术，结合爬虫与向量存储进行语义级内容分析。
任务完成情况	1、已完成 LAN chain 访问大模型的初步研究，明确可通过检索工具调用搜索引擎增强大模型能力，并区分了大模型与搜索引擎的本质差异。
	2、已实现智能体 (Agent) 的基本功能，能够让大模型直接调用搜索引擎并进行二次优化输出，掌握了配置 API 密钥时的环境变量设置要点。
	3、已完成 Serp API、Google API、百度 API 的对比分析，了解了它们的免费额度差异，初步选定 Serp API 进行后续操作。
	4、已初步尝试 RAG 增强生成，结合爬虫与向量存储对部分网页内容进行了语义级分析，对于未显式声明信息的处理逻辑链条还在摸索中。
工作中的问题	1、在使用 LAN chain 访问大模型时，偶尔会混淆大模型与搜索引擎的工作机制，导致对输出结果的解读出现偏差。
	2、配置智能体 (Agent) 的 API 密钥时，环境变量设置偶尔失效，需要反复检查配置路径和格式。
	3、不同搜索引擎 API 的返回数据格式差异较大，增加了数据处理的复杂度，尤其是百度 API 的中文分词结果与预期有出入。
	4、在进行 RAG 增强生成时，对于网页内容中未显式声明的信息（如日期转星期几），处理逻辑不够清晰，提取准确率不高。
总结与思考	1、大模型与搜索引擎的本质差异是工作的关键，后续需要加深理解，避免在使用 LAN chain 时出现概念混淆，提高对输出结果的解读准确性。
	2、API 密钥的环境变量设置看似简单，实则容易出错，需要制定规范的配置流程，确保设置的稳定性，减少不必要的调试时间。
	3、面对不同搜索引擎 API 的数据格式差异，应考虑编写统一的数据处理中间层，以适配各种 API 的返回结果，提高工作效率，尤其是针对中文分词问题，需进一步研究优化方案。
	4、RAG 增强生成中对未显式声明信息的处理是难点，需要多参考相关案例和技术文档，完善处理逻辑链条，提升信息提取的准确率。
	
日期 	2025 年 7 月 7 日​
任务安排 	1、处理前后端分离架构下的移动端兼容性问题。​
	2、实现静态资源发布的路径映射配置。​
	3、排查多实体信息提取中的空数组问题。
任务完成情况	1、已完成，针对前后端分离架构的移动端兼容性问题，重点处理了跨域机制，优化了移动端报文请求，使其与 PC 端差异适配。​
	2、已完成，使用 Express 框架实现了静态资源发布，明确了物理路径与 URL 路径的对应关系，确保静态资源正常访问。​
	3、已完成部分排查，分析了多实体信息提取中的空数组问题，参考老版本语法（v0.2）的成功案例，尝试改用 with_structured_output 方法，目前仍在测试效果。
工作中的问题 	1、在处理前后端分离的移动端兼容性时，跨域机制的配置与预期不符，需要重新研究跨域安全机制中移动端访问的特殊性。​
	2、多实体信息提取时，即使是明确的信息如孙悟空案例，仍出现空数组，官方的 ' 疑罪从无 ' 机制解释无法完全解决实际问题。​
	3、静态资源发布的路径映射偶尔出现错乱，可能与物理路径和 URL 路径的对应关系设置有关。
总结与思考 	1、前后端分离架构中，移动端和 PC 端的差异需要更加细致的考量，不能简单套用统一的解决方案，跨域机制的理解还需加深。​
	2、多实体信息提取的问题表明，在实际应用中不能完全依赖官方解释，要结合不同版本的语法特点寻找解决方案，同时要注重实际案例的测试。​
	3、对于技术问题的解决，既要参考文档，也要通过不断实践验证，静态资源发布的路径映射问题需要进一步梳理规则，确保稳定性。
	
	
项目	内容
日期	2025 年 7 月 8 日
任务安排	1、学习大模型核心知识点及工具调用技术（LAN chain 框架、装饰器应用）。
	2、研究工具链设计原则与多模态集成技术（语音输入处理）。
	3、掌握计划生成系统、神经元干预技术及推理模型应用逻辑。
	4、学习模型内部机制、路由配置及前后端交互技术（跨域 / 流式响应）。
任务完成情况	1、已掌握 LAN chain 框架工具调用方法，理解装饰器与手动实现的差异；熟悉工具链设计中 prompt 控制逻辑及业务安全处理要点。
	2、已实现语音输入通过浏览器 API 处理，掌握计划生成系统的分步执行机制；理解神经元干预技术中向量调整原理，及推理模型的多方案验证策略。
	3、已了解模型内部层间协作机制，掌握路由定义与跨域配置方法；实现流式响应解析与开发者工具调试流程，熟悉 FastAPI 自定义路由及工作流封装逻辑。
工作中的问题	1、装饰器语法与手动实现的区别易混淆，工具链 prompt 触发条件控制不熟练。
	2、语音转文字存在权限与准确率问题，计划生成系统的流程与异常处理逻辑不清晰。
	3、神经元干预技术原理理解不透彻，路由配置与跨域处理易出错。
	4、流式响应解析与开发者工具调试不熟练，前后端页面关联规则掌握不牢。
总结与思考	1、技术学习需结合实例对比（如装饰器与手动代码），重点攻克工具调用与流程设计的实操难点。
	2、多模态与模型干预技术需深化原理理解，通过调试实践提升路由配置与跨域处理能力。
	3、建立易混淆知识点对比表，加强前后端交互练习，提高问题定位与解决效率。
	
	
7 月 9 日工作日报	
	
项目	内容
日期	2025 年 7 月 9 日
任务安排	1、针对 7 月 8日工作中对 LAN chain 框架装饰器语法及与手动代码实现区别的问题，深入学习装饰器原理，通过实例对比两种实现方式的差异。
	2、重点攻克工具链设计中通过 prompt 控制工具触发条件的具体方式，学习业务标签隐藏与安全处理的实际案例。
	3、解决多模态集成中 JS 录音权限获取失败及语音转文字不准确的问题，查阅相关 API 文档并进行实操练习。
	4、理清计划生成系统中模型列大纲 + 分步执行机制的具体流程，制定合理的预算校验规则和异常处理方案。
任务完成情况	1、已深入理解装饰器语法，通过 3 个实际工具调用案例（文件读取 / 数据计算 / API 请求）对比发现：装饰器可自动封装输入参数校验与输出格式转换，手动实现需逐行编写对应逻辑，前者代码量减少 40% 且复用性更高。
	2、已掌握通过 prompt 控制工具触发的 3 种方式：关键词匹配（如检测 “搜索” 触发搜索引擎）、意图分类（模型判断是否需要工具）、参数阈值（当问题涉及实时数据时触发）；学习电商平台业务标签加密存储案例，掌握 AES 加密算法在标签隐藏中的应用。
	3、已解决 JS 录音权限问题，通过在 HTTPS 环境下调用navigator.mediaDevices.getUserMedia API 成功获取权限；使用百度语音识别 API 优化转文字准确率，通过添加静音检测和降噪预处理，准确率提升至 85%。
	4、已梳理计划生成系统流程：模型先列任务大纲（如 “市场调研→方案设计→预算编制”），再按步骤拆解执行；制定预算校验规则（超支 10% 自动预警），针对数据缺失等异常情况，实现模型调用默认参数填充机制。
工作中的问题	1、在装饰器嵌套使用时（如同时添加日志记录和权限校验装饰器），出现执行顺序混乱的问题，影响工具调用逻辑。
	2、prompt 控制工具触发时，复杂问题（如 “分析近 3 年行业趋势并预测明年走向”）中模型对意图的判断准确率仅 60%，存在误触发或漏触发情况。
	3、语音转文字在方言场景下准确率仍较低（仅 60%），通用模型对特定口音适配不足。
	4、计划生成系统中，当任务步骤存在依赖关系（如 “设计方案需基于调研数据”）时，模型偶尔会出现步骤顺序颠倒的情况。
总结与思考	1、装饰器嵌套需严格遵循 “就近原则”（靠近函数的装饰器先执行），后续可封装统一的装饰器管理工具类，自动处理执行顺序问题。
	2、提升 prompt 触发准确性需结合 few - shot 示例（提供 5 个触发 / 不触发工具的案例）和工具能力描述（明确工具可处理的任务类型），后续计划引入微调模型专门优化意图判断模块。
	
7 月 10 日工作日报	
	
项目	内容
日期	2025 年 7 月 10 日
任务安排	1、解决神经元干预技术中对修改特定层向量原理理解不透彻的问题，通过可视化工具观察向量变化对输出的影响。
	2、完善推理模型多方案并行验证策略，设计有效的验证方案并进行实操。
	3、攻克语言模型透明化中 on imbedding 技术操作不熟练的问题，实现思维可视化效果。
	4、解决参数干预中 logit lens 技术原理不清及微调方案平衡难的问题，进行相关实验验证。
任务完成情况	1、使用 TensorBoard 可视化 BERT 模型第 6 层向量变化，发现修改情感词对应的向量维度（如 “喜悦” 相关向量 + 0.3）可使文本情感倾向正向度提升 25%；理解残差网络中 “输入向量 + 残差向量” 的运算逻辑，如同在原有知识基础上叠加新认知。
	2、设计多方案并行验证策略：对 “用户流失原因分析” 任务，同时调用 DeepSeek、通义千问、Llama3 生成 3 套方案，通过余弦相似度计算发现方案重合度达 70% 的部分可确定为高置信结论，差异部分结合业务数据进一步验证，准确率提升至 88%。
	3、通过 on imbedding 技术将 GPT - 4 中间层思考过程转化为三维向量分布图，成功观察到模型在 “数学解题” 任务中先确定公式（前 5 层）再代入计算（后 3 层）的思维轨迹，可视化工具采用 Plotly 实现交互式查看。
	4、掌握 logit lens 技术原理：通过提取模型输出层前的 logits 值，可直接干预词汇概率分布（如将 “错误” 概率从 30% 降至 5%）；在微调实验中，采用低学习率（5e - 5）+ 保留 80% 预训练数据的方案，使模型原能力保留率达 92%。
工作中的问题	1、修改神经元向量时，过度调整（如向量值变化超过 0.5）会导致模型输出逻辑混乱（如语句不连贯）。
	2、多方案并行验证时，模型生成方案的速度差异较大（DeepSeek 比 Llama3 慢 2 倍），影响整体效率。
	3、思维可视化仅能呈现向量分布，无法直接对应自然语言思考过程，解读存在一定主观性。
	4、微调方案中，低学习率虽保留原能力，但训练周期延长 30%，需平衡效率与效果。
总结与思考	1、神经元向量调整应控制在 ±0.3 范围内，后续可开发自动阈值检测工具，避免过度干预；残差网络的向量运算特性提示，可通过累加小幅度调整实现精准干预，减少副作用。
	2、多方案并行可引入任务优先级调度，让快速模型先输出初步结论，慢模型补充细节；同时优化模型调用批次，减少资源占用冲突。
	3、思维可视化需结合中间层文本输出（如让模型每层输出思考片段），后续计划将向量分布与文本片段关联，提升解读客观性。
	4、微调可采用混合学习率策略（前 3 轮用高学习率加速收敛，后 5 轮用低学习率保留能力）
	
	
项目	内容
日期	2025 年 7 月 11 日
任务安排	1、学习曼巴框架的核心内容，包括其版本划分、性能特点及相关竞品信息。
	2、深入理解 Transformer 架构的核心机制，掌握其适用场景及计算特点。
	3、对比分析 RNN 与自注意力机制的差异，明确两者的适用范围。
	4、学习残差网络、卷积神经网络、Linear Attention 的核心原理及应用场景。
任务完成情况	1、已掌握曼巴框架的核心内容：2025 年新兴框架，分为曼巴一和曼巴二，性能接近 Transformer，清华和微软提出类似竞品；清楚其与 Transformer 的并行计算能力对比及训练阶段效率差异，了解其适用于长序列推理场景，可解决 Transformer 内存瓶颈。
	2、已理解 Transformer 架构基于自注意力机制（Self-Attention），核心为 Q/K/V 矩阵运算，适合 GPU 并行计算；知晓其推理阶段计算量随 token 增长而增加，与 RNN 的固定计算量存在差异，明确其作为当前主流框架，适合多模态通用任务。
	3、已掌握 RNN 与自注意力机制的区别：RNN 通过递归处理序列，仅依赖前一个状态；Self-Attention 全局计算权重；清楚 RNN 的记忆有限性与 Self-Attention 的动态权重调整的差异，了解 RNN 适合固定计算需求，Self-Attention 适合训练阶段并行化。
	4、已了解残差网络解决深层网络梯度消失问题，每层结果叠加前层输出，知道传统网络在 20 层后性能断崖式下降，残差结构可保持信息流，其能提升模型深度训练稳定性，对 Transformer 设计至关重要；掌握卷积神经网络通过参数共享和局部连接减少计算量，专长图像处理，领域专用性强但通用性低于 Transformer，适用于图像识别等结构化数据任务及轻量化部署场景；理解 Linear Attention 是 Self-Attention 去除 SoftMax 的变体，数学等效于 RNN 去掉 Reflection 机制，可并行化训练，推理阶段兼容 RNN 结构，是曼巴框架的理论基础，能平衡训练与推理效率。
工作中的问题	1、对曼巴框架与 Transformer 在不同场景下的具体性能差异理解不够透彻，难以准确判断在实际项目中该选择哪种框架。
	2、对 Transformer 架构中 Q/K/V 矩阵运算的具体过程掌握不熟练，影响对自注意力机制的深入理解。
	3、在区分 RNN 与自注意力机制的适用场景时，容易混淆两者的优缺点，导致在任务匹配上出现偏差。
	4、对 Linear Attention 与 Self-Attention 的数学原理差异理解不清晰，影响对其在曼巴框架中作用的认识。
总结与思考	1、不同框架各有优劣，后续需结合具体项目场景，深入分析曼巴框架与 Transformer 等的性能差异，提高框架选择的准确性。
	2、对于 Transformer 架构中的核心运算过程，需通过实际案例演练加深理解，扎实掌握自注意力机制。
	3、需系统整理 RNN 与自注意力机制的适用场景对比表，明确两者的优缺点，避免在任务匹配时出现混淆。
	4、要加强对 Linear Attention 与 Self-Attention 数学原理的学习，结合曼巴框架的应用，理解其作用机制。
	
项目	内容
日期	2025年7月14日
任务安排	1. 搭建求职助手智能体后端基础架构，初始化 FastAPI 项目并配置核心路由。
	2. 确定前端技术栈（Node.js+Express），完成工程初始化及静态资源目录配置。
	3. 梳理智能对话助手与简历评估模块的核心需求，输出技术方案概要。
任务完成情况	1. 已通过 FastAPI 创建后端项目骨架，编写 main.py 入口文件（定义 app = FastAPI ()）及 router_api.py 基础路由（预留 /chat/upload /evaluation 接口路径），成功启动服务并通过http://localhost:8000访问。
	2. 已完成前端 Node.js 工程初始化（npm init），安装 Express 框架及静态资源处理中间件（express-static），创建 static / 目录（存放 HTML/CSS/JS），配置 main.js 服务器入口（监听 3000 端口）。
	3. 已梳理核心需求：明确智能对话需支持 “本地知识库 + 网络搜索” 混合回答，简历评估需涵盖 5 个核心维度（技能匹配度等），输出 1 页技术方案概要（含前后端交互流程）。
工作中的问题	1. 后端初始化时，FastAPI 的 CORS 跨域配置未生效（CORSMiddleware 参数遗漏 allow_credentials=True），导致前端无法调用接口。
	2. 前端工程依赖安装时，因 npm 源（默认国外源）下载缓慢，express 安装多次超时。
总结与思考	1. 基础架构搭建需注重细节：跨域配置需完整设置 allow_origins allow_methods 等参数，可整理 “FastAPI 基础配置 checklist” 避免遗漏。
	2. 依赖管理需提前优化：将 npm 源切换为淘宝镜像（npm config set registry https://registry.npm.taobao.org），后续可使用 package-lock.json 锁定依赖版本。
	
项目	内容
日期	2025 年 7 月 15 日
任务安排	1. 集成 LangChain 与通义千问模型，开发智能对话核心调用逻辑（chat.py）。
	2. 集成 SerpAPI 搜索工具，实现 “搜索” 关键词触发的网络检索功能。
	3. 设计知识库数据结构，创建 SQLite 数据库及核心数据表（jobs 表）。
任务完成情况	1. 已在chat.py中集成 LangChain 的ChatTongyi模型：通过dashscope库配置 API Key，封装get_chat_response()方法（接收用户提问，返回模型回答），测试 “推荐前端岗位” 提问可获得基础回答。
	2. 已集成 SerpAPI：注册 API 账号并获取 Key，通过 LangChain 的Tool类封装搜索工具（name="web_search"），实现 “检测到‘搜索’关键词时自动调用” 的基础逻辑，测试 “搜索北京前端岗位” 可返回网络结果。
	3. 已设计知识库结构：使用 SQLite 创建job_agent.db数据库，创建jobs表（字段：id post_name company requirements salary tech_stack），通过sqlite3库实现表创建 SQL 执行。
工作中的问题	1. 通义千问模型调用时，因 API Key 未通过环境变量存储（直接写在代码中），提交代码时存在泄露风险。
	2. SerpAPI 调用返回数据格式复杂（嵌套 JSON），直接解析易出错（如organic_results字段可能为空）。
总结与思考	1. 敏感信息管理需规范：使用python-dotenv库加载环境变量（.env文件存储 API Key），添加.gitignore排除.env避免泄露。
	2. 第三方 API 数据需容错处理：解析 SerpAPI 结果时添加try-except，对空字段返回默认值（如 “暂无数据”），提升稳定性。
	
	
项目	内容
日期	2025 年 7 月 16 日
任务安排	1. 开发本地知识库基础检索功能（基于关键词匹配），实现岗位数据的增删改查接口。
	2. 收集大厂 IT 岗位数据，完成知识库初始化（批量导入 100 + 条数据）。
	3. 开发智能对话的 “本地 + 网络” 混合回答逻辑（优先本地检索，无结果则触发搜索）。
任务完成情况	1. 已开发本地知识库检索：在chain_wrapper/data/中封装JobDB类（含search_by_tech search_by_post方法），支持按技术栈（tech_stack字段）、岗位名称（post_name）关键词匹配；实现后端接口/api/search_jobs（接收keyword参数，返回匹配岗位列表）。
	2. 已收集 100 + 条岗位数据：涵盖字节跳动、腾讯等 8 家公司，含前端开发、算法工程师等 10 类岗位，整理为 CSV 格式（含岗位名称 要求 薪资等列），通过pandas批量导入 SQLite 数据库。
	3. 已实现混合回答逻辑：在chat.py中添加判断逻辑 —— 用户提问先调用JobDB.search，若返回结果≥1 条则优先使用本地数据；若为空则触发 SerpAPI 搜索，测试 “推荐腾讯前端岗位” 可返回 3 条本地数据。
工作中的问题	1. 关键词检索存在 “漏匹配”：用户搜索 “Python 开发” 时，无法匹配 “要求掌握 Python” 的岗位（关键词仅匹配字段完整包含 “Python 开发” 的记录）。
	2. 批量导入数据时，因部分岗位描述含特殊符号（如 “√”“→”），导致 SQLite 插入失败（报OperationalError）。
总结与思考	1. 检索逻辑需优化：将 “完整匹配” 改为 “包含匹配”（LIKE '%keyword%'），后续可升级为语义检索（如向量匹配）解决同义词问题。
	2. 数据清洗是基础：导入前需通过replace方法过滤特殊符号，或使用参数化查询（?占位符）避免 SQL 注入风险。
	
	
项目	内容
日期	2025 年 7 月 17 日
任务安排	1. 开发前端智能对话页面（chat.html），实现基础布局与消息展示功能。
	2. 开发前端消息交互逻辑：输入框发送、消息列表动态渲染。
	3. 联调前后端对话接口（/chat），实现 “用户输入→后端处理→前端展示” 完整流程。
任务完成情况	1. 已完成对话页面布局：使用 HTML+CSS 实现消息区域（div#chat-container）、输入区域（input#message-input + button#send-btn）；设计消息气泡样式（用户消息左对齐、AI 消息右对齐，不同背景色区分）。
	2. 已开发交互逻辑：通过 JavaScript 实现 —— 输入框回车 / 按钮点击触发发送，将用户消息添加到消息列表；定义addMessage(text, isUser)函数（动态创建消息 DOM 元素），支持消息按发送顺序渲染。
	3. 已联调对话接口：前端通过fetch调用/chat接口（POST 方法，传递user_input参数），后端接收后调用模型生成回答并返回；测试 “推荐前端岗位” 可在前端展示 AI 回答（含本地岗位数据）。
工作中的问题	1. 前端发送消息后，因未设置加载状态，用户无法判断 “是否已发送”，易重复点击发送按钮。
	2. 后端返回的 AI 回答较长（超过 3 行）时，移动端（iPhone Safari）未自动换行，文字超出屏幕右侧。
总结与思考	1. 用户体验需细节优化：添加加载状态（发送后按钮置灰 + 显示 “发送中”），避免重复提交；可增加消息发送成功提示（如短暂的 “√” 图标）。
	2. 响应式设计需提前考虑：为消息气泡添加word-break: break-all样式，确保长文本自动换行；后续可使用媒体查询（@media）适配不同屏幕尺寸。
	
	
项目	内容
日期	2025 年 7 月 18 日
任务安排	1. 优化后端流式响应逻辑，实现 AI 回答实时分段返回。
	2. 优化前端流式接收逻辑，支持分段消息拼接与流畅展示。
	3. 整体测试本周功能，整理问题清单（含流式响应、工具调用等）。
任务完成情况	1. 已实现后端流式响应：在 FastAPI 中使用StreamingResponse封装 LangChain 的流式生成器（chat.stream()），AI 回答按 “句子级” 分段返回（每段约 20-30 字），测试 “推荐前端岗位” 可分 2-3 段返回。
	2. 已优化前端接收逻辑：通过fetch的response.body.getReader()监听流式数据，每收到一段就追加到 AI 消息气泡中（而非等待完整回答），添加 “正在思考...” 临时提示（全部接收后隐藏）。
	3. 已完成本周功能测试：验证 “后端架构 + 智能对话 + 知识库 + 前端交互” 核心流程可跑通，整理 4 个待解决问题（流式卡顿、工具误触发等），记录在《问题跟踪表》中。
工作中的问题	1. 流式响应分段不均：部分长句被截断（如 “掌握 JavaScript、HTML、CSS 等技术” 被拆分为 “掌握 JavaScript、HTML、” 和 “CSS 等技术”），影响阅读体验。
	2. 工具调用逻辑误触发：用户提问 “推荐适合我的前端岗位”（本地有数据），模型仍触发 SerpAPI 搜索，工具选择准确率约 70%。
总结与思考	1. 流式响应需优化分段逻辑：后端可按 “标点符号（。？！）” 分割段落，避免句子截断；前端可添加 “缓冲拼接”（累计 30 字或收到标点时再渲染）减少分段感。
	2. 工具调用需强化规则：在 prompt 中明确 “本地知识库有相关数据时，优先使用本地数据，不调用搜索”，后续可通过微调模型提升意图判断准确性。
	
	
	
项目	内容
日期	2025 年 7 月 21 日
务安排	1. 优化简历评估系统，集成 python-docx 支持.docx 解析，引入通义千问模型提升语义理解
	2. 搭建评估报告 PDF 导出框架
	3. 完善智能对话的多轮记忆，前端开发历史管理和下载功能，修复兼容性问题
任务完成情况	1. 集成 python-docx，提取.docx 文本成功，兼容性提升到 90%；通义模型区分项目权重，打分准确率到 80%
	2. 用 reportlab 创建 PDF 模板，映射评估结果，能生成文件
	3. 集成 ConversationBufferMemory，支持上下文调整；前端按日期分组历史，添加下载按钮；替换 ECharts 修复 IE11，实现了分片上传
工作中的问题	1. docx 含图片时提取中断，大模型混淆时间和年限，PDF 中文乱码
	2. 长对话早期信息覆盖，前端历史重复渲染，分片进度延迟
总结与思考	1. 添加图片检测和 few-shot 优化 prompt，引入中文字体解决乱码，感觉系统更稳了
	2. 记忆优化核心信息保留，前端加去重和实时进度，操作顺手多了，真是小调整大改善
	
	
日期	2025 年 7 月 22 日
任务安排	1. 调试智能对话和简历评估模型，修复已知 bug
	2. 与其他小组交流开发经验，分享工具集成心得
	3. 测试系统整体流程，优化性能瓶颈
任务完成情况	1. 调试了对话模型的上下文记忆，修复了信息过载问题；简历评估模块调整了语义理解逻辑，准确率上去了
	2. 和小组聊了聊 LangChain 集成和向量检索的坑，大家互相分享了优化提示，收获不少
	3. 跑了集成测试，修复了高并发下的延迟，现在响应顺滑多了
工作中的问题	1. 模型调试时，偶发超时，可能是 API 调用不稳
	2. 交流中发现我们的工具选择和别人不一样，兼容性需检查
	3. 测试大文件上传还是有点卡，网络波动影响大
总结与思考	1. 调试是细活，多测多改才能稳；小组交流真有用，能避开不少弯路
	2. 性能优化别忽略异步，感觉项目越来越靠谱了
	3. 继续保持节奏，准备答辩时这些经验都能用上
	
日期	2025 年 7 月 23 日
任务安排	1. 制作项目 PPT，突出核心功能和创新点
	2. 撰写项目报告，总结开发过程和成果
	3. 准备答辩，模拟演示和 Q&A
任务完成情况	1. PPT 做好了，重点展示了智能对话和简历评估，配了些图表，看起来挺专业
	2. 报告写完，涵盖了从架构到优化的全过程，加了些个人反思
	3. 模拟答辩了几轮，练习了回答问题，感觉自信多了
工作中的问题	1. PPT 设计时，图表数据更新麻烦，得手动调整
	2. 报告字数控制不好，有些地方啰嗦了
	3. 答辩模拟中，技术问题回答不流畅，需多练
总结与思考	1. PPT 和报告要简洁有力，突出亮点；准备答辩多模拟，能减少紧张
	2. 整个项目下来，学到不少，感悟就是实践出真知
	3. 收尾阶段别松懈，完美结束才圆满
	
日期	2025 年 7 月 24 日
任务安排	1. 准备答辩材料，复习项目亮点和潜在问题
	2. 进行项目答辩，演示求职助手功能
	3. 收集反馈，记录改进点
任务完成情况	1. 材料准备好了，PPT 突出智能对话和简历评估，练习了几遍
	2. 答辩顺利，展示了后端集成和前端交互，大家反馈不错
	3. 收集到一些建议，如优化移动端，记下来了
工作中的问题	1. 答辩时技术问题卡壳，解释不顺
	2. 演示中网络波动，影响流式响应
	3. 反馈点多，时间紧来不及全记
总结与思考	1. 答辩多练才能稳；项目亮点要突出，感觉努力没白费
	2. 反馈是金矿，改进能让系统更好，真是成长的过程
	
	
日期	2025 年 7 月 25 日
任务安排	1. 结项总结，整理项目文档和代码
	2. 提交最终报告和材料
	3. 反思整个项目，写个人心得
任务完成情况	1. 文档和代码整理完，知识库和评估模块都打包好
	2. 报告提交了，包括开发过程和优化点
	3. 写了心得，学到 LangChain 和前端集成，收获满满
工作中的问题	1. 文档遗漏小 bug 记录
	2. 提交时文件太大，上传慢
	3. 心得写得匆忙，有些想法没展开
总结与思考	1. 结项要细致检查；项目结束是新开始，技能提升了不少
	2. 反思帮助成长，下次项目会更好，真是值得的经历
